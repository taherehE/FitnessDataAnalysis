{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn import scatterplot as scatter\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#import sklearn.metrics.scorer as scorer\n",
    "\n",
    "\n",
    "#reading data from file\n",
    "\n",
    "#df,meta=pyreadstat.read_sav(\"C:/Users/APPLE/Desktop/Folders/sana thesis/SHAHNAZ-meysam-tekvando.sav\")\n",
    "df=pd.read_excel(\"C:/Users/APPLE/Desktop/Folders/sana thesis/SHAHNAZ-meysam-tekvandolabelmodified.xls\")\n",
    "\n",
    "#preprocessing operations such as converting Nan values to zero,\n",
    "#converting fields without value to zero,\n",
    "#removing ID,fisrtname, and familyname columns from dataset\n",
    "\n",
    "features_name=df.columns\n",
    "data=np.array(df)\n",
    "df=pd.DataFrame(data=data,columns=features_name)\n",
    "df=df.drop(['firstname','familyname','year'],axis=1)\n",
    "\n",
    "# keep only women samples\n",
    "df1=df\n",
    "for l in range(2559):\n",
    "    if (df1.iloc[l,0]==1.0):\n",
    "        df=df.drop([l])    \n",
    "\n",
    "true_labels=df.iloc[:,-1]\n",
    "df=df.drop(['label','gender'],axis=1)\n",
    "features_name=df.columns\n",
    "\n",
    "true_labels=true_labels.fillna(0)\n",
    "for i in range(len(true_labels)):\n",
    "    if (true_labels.iloc[i]==0):\n",
    "        true_labels.iloc[i]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Concani','burus','wingetAP','WingtePP','ricaveri','oneMayl','pareshTool','ghodratPanjeh','barfix','jaheshJanebi',\n",
    "            'FlexibleShoulder','RTshenidari','tawanBiHavazi','biHAVA1609','Do1600','yekMayl',\n",
    "            'metr540','taadol'],axis=1)\n",
    "features_name=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "data=np.array(df)\n",
    "data=data.astype('float')\n",
    "data[data==0.0]=np.nan\n",
    "df=pd.DataFrame(data=data,columns=features_name)\n",
    "\n",
    "strategy=('mean','median')\n",
    "simpleimputer=SimpleImputer(missing_values=np.nan, strategy=strategy[0])\n",
    "data1=simpleimputer.fit_transform(df)\n",
    "#df1=pd.DataFrame(data=data1,columns=features_name)\n",
    "#simpleimputer=SimpleImputer(missing_values=0.0, strategy=strategy[0])\n",
    "#data1=simpleimputer.fit_transform(df1)\n",
    "\n",
    "\n",
    "knnimputer=KNNImputer(missing_values=np.nan)\n",
    "data2=knnimputer.fit_transform(df)\n",
    "#df2=pd.DataFrame(data=data2,columns=features_name)\n",
    "#knnimputer=KNNImputer(missing_values=0.0)\n",
    "#data2=knnimputer.fit_transform(df2)\n",
    "\n",
    "estimators=[BayesianRidge(),\n",
    "            DecisionTreeRegressor(max_features='sqrt',random_state=0),\n",
    "            ExtraTreesRegressor(n_estimators=10, random_state=0),\n",
    "            KNeighborsRegressor(n_neighbors=15)\n",
    "           ]\n",
    "\n",
    "iterativeimputer=IterativeImputer(missing_values=np.nan, random_state=0, estimator=estimators[3], n_nearest_features=5)\n",
    "data3=iterativeimputer.fit_transform(df)\n",
    "#df3=pd.DataFrame(data=data3,columns=features_name)\n",
    "#iterativeimputer=IterativeImputer(missing_values=0.0, random_state=0, estimator=estimators[0], n_nearest_features=5)\n",
    "#data3=iterativeimputer.fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing standardScaler as preprocessing\n",
    "\n",
    "scaler=StandardScaler(with_mean=False)\n",
    "data_scaled=scaler.fit_transform(data2)\n",
    "df=pd.DataFrame(data=data_scaled,columns=features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep 60% of labeled data for test\n",
    "true_labels=true_labels.astype(float)\n",
    "true_labels.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df['label']=true_labels\n",
    "df3=df\n",
    "df4=df\n",
    "\n",
    "# making df3 as a labeled set\n",
    "for l in range(len(df)):\n",
    "    if(df.iloc[l,-1]==-1):\n",
    "        df3=df3.drop([l])\n",
    "        \n",
    "df3_labels=df3.iloc[:,-1]\n",
    "df5=df3\n",
    "#df3=df3.drop(['label'],axis=1)\n",
    "X_train_labeled,X_test=train_test_split(df3,test_size=0.60,random_state=42)\n",
    "\n",
    "#making df4 as an unlabeled set\n",
    "for l in range(len(df)):\n",
    "    for i in range(len(df5)):\n",
    "        if (df.iloc[l,:].equals(df5.iloc[i,:])):\n",
    "            df4=df4.drop([l])\n",
    "            break\n",
    "\n",
    "X_train=df4\n",
    "X_train_unlabeled=X_train\n",
    "X_train=X_train.append(X_train_labeled)\n",
    "\n",
    "Y_train_labeled=X_train_labeled.iloc[:,-1]\n",
    "X_train_labeled=X_train_labeled.drop(['label'],axis=1)\n",
    "Y_train_labeled=Y_train_labeled.to_frame()\n",
    "Y_train_labeled=Y_train_labeled.astype(float)\n",
    "Y_train_labeled=Y_train_labeled.reset_index(drop=True)\n",
    "X_train_labeled=X_train_labeled.astype(float)\n",
    "X_train_labeled=X_train_labeled.reset_index( drop=True)\n",
    "\n",
    "X_train_unlabeled=X_train_unlabeled.drop(['label'],axis=1)\n",
    "X_train_unlabeled=X_train_unlabeled.astype(float)\n",
    "X_train_unlabeled=X_train_unlabeled.reset_index( drop=True)\n",
    "\n",
    "\n",
    "\n",
    "Y_train=X_train.iloc[:,-1]\n",
    "Y_test=X_test.iloc[:,-1]\n",
    "X_train=X_train.drop(['label'],axis=1)\n",
    "X_test=X_test.drop(['label'],axis=1)\n",
    "Y_train=Y_train.astype(float)\n",
    "Y_train=Y_train.reset_index(drop=True)\n",
    "Y_test=Y_test.astype(float)\n",
    "Y_test=Y_test.reset_index( drop=True)\n",
    "X_train=X_train.astype(float)\n",
    "X_test=X_test.astype(float)\n",
    "X_train=X_train.reset_index( drop=True)\n",
    "X_test=X_test.reset_index( drop=True)\n",
    "Y_train=Y_train.to_frame()\n",
    "Y_test=Y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:288: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.46      0.50      0.48        12\n",
      "         2.0       0.33      0.33      0.33         6\n",
      "         3.0       0.25      0.20      0.22         5\n",
      "\n",
      "    accuracy                           0.39        23\n",
      "   macro avg       0.35      0.34      0.35        23\n",
      "weighted avg       0.38      0.39      0.39        23\n",
      "\n",
      "Confusion matrix\n",
      "[[6 3 3]\n",
      " [4 2 0]\n",
      " [3 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:288: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.53      0.89      0.67         9\n",
      "         2.0       1.00      0.10      0.18        10\n",
      "         3.0       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.48        23\n",
      "   macro avg       0.61      0.50      0.40        23\n",
      "weighted avg       0.69      0.48      0.40        23\n",
      "\n",
      "Confusion matrix\n",
      "[[8 0 1]\n",
      " [5 1 4]\n",
      " [2 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.37      0.88      0.52         8\n",
      "         2.0       0.00      0.00      0.00         3\n",
      "         3.0       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.35        23\n",
      "   macro avg       0.46      0.32      0.22        23\n",
      "weighted avg       0.65      0.35      0.26        23\n",
      "\n",
      "Confusion matrix\n",
      "[[7 1 0]\n",
      " [3 0 0]\n",
      " [9 2 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:288: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    }
   ],
   "source": [
    "data=np.array(X_train)\n",
    "label=np.array(Y_train)\n",
    "\n",
    "#feature extraction algorithms\n",
    "\n",
    "#svd = TruncatedSVD(n_components=2, algorithm='randomized')\n",
    "#data_extracted=svd.fit_transform(data)\n",
    "\n",
    "#nmf=NMF(n_components=2, init='random', random_state=0)\n",
    "#data_extracted=nmf.fit_transform(data)\n",
    "\n",
    "pca=PCA(n_components=2)\n",
    "data_extracted=pca.fit_transform(data)\n",
    "\n",
    "#kpca=KernelPCA(n_components=2,kernel='poly')\n",
    "#data_extracted=kpca.fit_transform(data)\n",
    "\n",
    "#lda=LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "#data_extracted=lda.fit_transform(data)\n",
    "\n",
    "#kpca=KernelPCA(n_components=2,kernel='cosine')\n",
    "#data_extracted=kpca.fit_transform(data_extracted)\n",
    "\n",
    "#fastICA=FastICA(n_components=2, random_state=0)\n",
    "#data_extracted=fastICA.fit_transform(data)\n",
    "\n",
    "#fa=FactorAnalysis(n_components=2, random_state=0)\n",
    "#data_extracted=fa.fit_transform(data)\n",
    "\n",
    "#dl=DictionaryLearning(n_components=2, random_state=0, fit_algorithm='cd',transform_algorithm='lasso_cd')\n",
    "#data_extracted=dl.fit_transform(data)\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Kfold splitting \n",
    "#kfold=KFold(n_splits=5, random_state=1)\n",
    "#k=0\n",
    "#for train, test in kfold.split(data_extracted):\n",
    "#    k=k+1\n",
    "#    label_propagation_model=LabelPropagation()\n",
    "#    label_propagation_model.fit(data_extracted[train],label[train])\n",
    "#    test_indices_truelabeled_list=[]\n",
    "#    test_true_labels=[]\n",
    "#    test_data_extracted=data_extracted[test]\n",
    "#    for l in range(len(data_extracted[test])):\n",
    "#        if (label[train][l]!=-1):\n",
    "           #labeled_data_extracted.iloc[i,:]=test_data_extrated.iloc[l,:]\n",
    "#            test_indices_truelabeled_list.append(l)\n",
    "#            test_true_labels.append(label[train][l])\n",
    "            \n",
    "            \n",
    "#    predicted_labels=label_propagation_model.transduction_[test_indices_truelabeled_list]\n",
    "#    cm=confusion_matrix(test_true_labels,predicted_labels,labels=label_propagation_model.classes_)\n",
    "#---------------------------------------------------------------------------------------\n",
    "#cl=LabelPropagation(kernel=\"rbf\",gamma=15,n_neighbors=4)\n",
    "cl=LabelSpreading(kernel=\"knn\",n_neighbors=8)\n",
    "cvresult1=crossvalidationSSL(data_extracted,label,cl,\"test\",3)\n",
    "#cl=crossvalidationSSL(data_extracted,label,svc,\"train\",3)\n",
    "#cvrsult2=crossvaidationSSL(X,y,classifier,measures,leaveout,k,repeats,n_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.44      0.63      0.52        38\n",
      "         2.0       0.55      0.24      0.33        46\n",
      "         3.0       0.29      0.43      0.35        21\n",
      "\n",
      "    accuracy                           0.42       105\n",
      "   macro avg       0.43      0.43      0.40       105\n",
      "weighted avg       0.46      0.42      0.40       105\n",
      "\n",
      "confusion_matrix\n",
      "[[24  5  9]\n",
      " [22 11 13]\n",
      " [ 8  4  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\APPLE\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "data_test=np.array(X_test)\n",
    "y_true=np.array(Y_test)\n",
    "Y_train=np.array(Y_train)\n",
    "data_train=np.array(X_train)\n",
    "#data_train=np.array(X_train_labeled)\n",
    "whole_data=np.array(df)\n",
    "\n",
    "#pca=PCA(n_components=2)\n",
    "#train_data_extracted=pca.fit_transform(data_train)\n",
    "#test_data_extracted=pca.fit_transform(data_test)\n",
    "#whole_data_extracted=pca.fit_transform(whole_data)\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, algorithm='randomized')\n",
    "train_data_extracted=svd.fit_transform(data_train)\n",
    "test_data_extracted=svd.fit_transform(data_test)\n",
    "whole_data_extracted=svd.fit_transform(whole_data)\n",
    "\n",
    "#nmf=NMF(n_components=2, init='random', random_state=0)\n",
    "#train_data_extracted=nmf.fit_transform(data_train)\n",
    "#test_data_extracted=nmf.fit_transform(data_test)\n",
    "#whole_data_extracted=nmf.fit_transform(whole_data)\n",
    "\n",
    "#lda=LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "#train_data_extracted=lda.fit_transform(data_train)\n",
    "#test_data_extracted=lda.fit_transform(data_test)\n",
    "#whole_data_extracted=lda.fit_transform(whole_data)\n",
    "\n",
    "#kpca=KernelPCA(n_components=2,kernel='cosine')\n",
    "#train_data_extracted=kpca.fit_transform(data_train)\n",
    "#test_data_extracted=kpca.fit_transform(data_test)\n",
    "#whole_data_extracted=kpca.fit_transform(whole_data)\n",
    "    \n",
    "#fastICA=FastICA(n_components=2, random_state=0)\n",
    "#train_data_extracted=fastICA.fit_transform(data_train)\n",
    "#test_data_extracted=fastICA.fit_transform(data_test)\n",
    "#whole_data_extracted=fastICA.fit_transform(whole_data)\n",
    "\n",
    "cl=LabelSpreading(kernel=\"knn\",gamma=20,n_neighbors=7)\n",
    "#cl=LabelPropagation(kernel=\"rbf\",gamma=15,n_neighbors=6)\n",
    "\n",
    "cl.fit(train_data_extracted,Y_train)\n",
    "y_predicted=cl.predict(test_data_extracted)\n",
    "cm=confusion_matrix(y_true, y_predicted, labels=cl.classes_)\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_predicted))\n",
    "print(\"confusion_matrix\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the result\n",
    "data_test=np.array(X_test)\n",
    "#y_true=np.array(Y_test)\n",
    "#Y_test=Y_test.iloc[:,-1]\n",
    "data_train=np.array(X_train)\n",
    "#data_train=np.array(X_train_labeled)\n",
    "whole_data=np.array(df)\n",
    "\n",
    "pca=PCA(n_components=2)\n",
    "train_data_extracted=pca.fit_transform(data_train)\n",
    "test_data_extracted=pca.fit_transform(data_test)\n",
    "whole_data_extracted=pca.fit_transform(whole_data)\n",
    "\n",
    "#svd = TruncatedSVD(n_components=2, algorithm='randomized')\n",
    "#train_data_extracted=svd.fit_transform(data_train)\n",
    "#test_data_extracted=svd.fit_transform(data_test)\n",
    "#whole_data_extracted=svd.fit_transform(whole_data)\n",
    "\n",
    "#fastICA=FastICA(n_components=2, random_state=0)\n",
    "#train_data_extracted=fastICA.fit_transform(data_train)\n",
    "#test_data_extracted=fastICA.fit_transform(data_test)\n",
    "#whole_data_extracted=fastICA.fit_transform(whole_data)\n",
    "\n",
    "\n",
    "#labelspreading=LabelSpreading(kernel='knn',gamma=8, n_neighbors=7)\n",
    "#learntransductive(train_data_extracted,Y_train,test_data_extracted,Y_test,whole_data_extracted,true_labels,\n",
    "#                  labelspreading,\"LabelSpreading\",\"test data\",\"knn,n_neighbors=7,SVD\")\n",
    "labelpropagation=LabelPropagation(kernel='rbf',gamma=15)\n",
    "\n",
    "learntransductive(train_data_extracted,Y_train,test_data_extracted,Y_test,whole_data_extracted,true_labels,labelpropagation,\"LabelPropagation\",\"test data\",\"rbf,gamma=15,PCA\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learntransductive(data_train_extracted,Y_train,data_test_extracted,y_true,whole_data_extracted,true_labels,\n",
    "                      classifier,methodname,kindofdata,kernel):\n",
    "\n",
    "    \n",
    "    classifier.fit(whole_data_extracted,true_labels)\n",
    "    kindofdata=\"whole data\"\n",
    "    output_labels=classifier.transduction_\n",
    "    plottransductive(whole_data_extracted,true_labels,output_labels,kindofdata,methodname,kernel)\n",
    "    kindofdata=\"test data\"\n",
    "    classifier.fit(data_train_extracted,Y_train)\n",
    "    y_predicted=classifier.predict(data_test_extracted)\n",
    "    plottransductive(data_test_extracted,y_true,y_predicted,kindofdata,methodname,kernel)\n",
    "    \n",
    "    \n",
    "def plottransductive(data,true_labels,output_labels,kindofdata,methodname,kernel):\n",
    "\n",
    "    #plot the result\n",
    "    \n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(data[true_labels==1,0],data[true_labels==1,1],color='navy',marker='s', lw=0, label=\"gold medal\", s=10)\n",
    "    plt.scatter(data[true_labels==2,0],data[true_labels==2,1],color='c',marker='s', lw=0, label=\"silver medal\", s=10)\n",
    "    plt.scatter(data[true_labels==3,0],data[true_labels==3,1],color='r',marker='s', lw=0, label=\"bronze medal\", s=10)\n",
    "    plt.scatter(data[true_labels==-1,0],data[true_labels==-1,1],color='darkorange',marker='.', lw=0, label=\"unknown labels\", s=10)\n",
    "    plt.legend(scatterpoints=1, shadow=False, loc='upper right')\n",
    "    plt.title(\"Raw data (3 classes=gold,silvar and bronze)\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    output_label_array = np.asarray(output_labels)\n",
    "    gold_numbers = np.where(output_label_array == 1)[0]\n",
    "    siver_numbers = np.where(output_label_array == 2)[0]\n",
    "    bronze_numbers = np.where(output_label_array == 3)[0]\n",
    "\n",
    "    plt.scatter(data[gold_numbers, 0], data[gold_numbers, 1], color='navy',\n",
    "            marker='s', lw=0, s=10, label=\"gold medal\")\n",
    "    plt.scatter(data[siver_numbers, 0], data[siver_numbers, 1], color='c',\n",
    "            marker='s', lw=0, s=10, label=\"silver medal\")\n",
    "    plt.scatter(data[bronze_numbers, 0], data[bronze_numbers, 1], color='r',\n",
    "            marker='s', lw=0, s=10, label=\"bronze medal\")\n",
    "    plt.legend(scatterpoints=1, shadow=False, loc='upper right')\n",
    "    plt.title(\"Labels of \"+kindofdata+\" learned with \"+methodname+\" (kernel=\"+kernel+\")\")\n",
    "\n",
    "    plt.subplots_adjust(left=0.07, bottom=0.07, right=0.93, top=0.92)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidationSSL(X,y,classifier,leaveout,k):\n",
    "    df=pd.DataFrame(X)\n",
    "    df['label']=y\n",
    "    df2=df\n",
    "    df3=df\n",
    "    #making df2 as a labeled DataFrame:\n",
    "    for l in range(len(df)):\n",
    "        if(df.iloc[l,-1]==-1):\n",
    "            df2=df2.drop([l])\n",
    "    #making df3 as an unLabeled DataFrame:\n",
    "    for l in range(len(df)):\n",
    "        for i in range(len(df2)):\n",
    "            if (df.iloc[l,:].equals(df2.iloc[i,:])):\n",
    "                df3=df3.drop([l])\n",
    "    if (leaveout==\"test\"):\n",
    "        #making validation and train sets:\n",
    "        #using labeled sets just for validation and \n",
    "        #using whole unlabeled set plus each fold for training in each iteration.\n",
    "        validationDataFrameList=np.array_split(df2,k)\n",
    "        validationDataFrameList2=validationDataFrameList\n",
    "        trainDataFrameList=[None]*k\n",
    "        for l in range(k):\n",
    "            trainDataFrameList[l]=df3\n",
    "            \n",
    "        for l in range(k):\n",
    "            removed=validationDataFrameList.pop()\n",
    "            trainDataFrameList[l]=trainDataFrameList[l].append(validationDataFrameList)\n",
    "            validationDataFrameList.insert(0,removed)\n",
    "        validationDataFrameList2.reverse()\n",
    "        for l in range(k):\n",
    "            cl=classifier\n",
    "            y=trainDataFrameList[l].iloc[:,-1]\n",
    "            X=np.array(trainDataFrameList[l].drop(['label'],axis=1))\n",
    "            cl.fit(X,y)\n",
    "            y_true=validationDataFrameList2[l].iloc[:,-1]\n",
    "            removedValidationDataFrame=validationDataFrameList2[l].drop(['label'],axis=1)\n",
    "            y_predicted=cl.predict(removedValidationDataFrame)\n",
    "            \n",
    "            cm = confusion_matrix(y_true, y_predicted, labels=cl.classes_)\n",
    "            \n",
    "            print(classification_report(y_true, y_predicted))\n",
    "\n",
    "            print(\"Confusion matrix\")\n",
    "            print(cm)\n",
    "    elif (leaveout=='train'):\n",
    "        #making train and validation sets:\n",
    "        #using k-1 labeled sets for training and one set for validation in each iteration\n",
    "        foldDataFrameList=np.array_split(df2,k)\n",
    "        foldDataFrameList2=foldDataFrameList\n",
    "        trainDataFrameList=[None]*k\n",
    "        for l in range(k):\n",
    "            removed=foldDataFrameList.pop()\n",
    "            trainDataFrameList[l]=foldDataFrameList\n",
    "            foldDataFrameList.insert(0,removed)\n",
    "        foldDataFrameList2.reverse()\n",
    "        for i in range(k):\n",
    "            cl=classifier\n",
    "            temp=trainDataFrameList[i]\n",
    "            trainDataFrame=pd.DataFrame()\n",
    "            for j in range(k):\n",
    "                trainDataFrame=trainDataFrame.append(temp[j],ignore_index=True)\n",
    "            X=np.array(trainDataFrame.drop(['label'],axis=1))\n",
    "            y=trainDataFrame.iloc[:,-1]\n",
    "            cl.fit(X,y)\n",
    "            y_true=foldDataFrameList2[i].iloc[:,-1]\n",
    "            validationDataFrame=foldDataFrameList2[i].drop(['label'],axis=1)\n",
    "            y_predicted=cl.predict(validationDataFrame)\n",
    "            \n",
    "            cm = confusion_matrix(y_true, y_predicted, labels=cl.classes_)\n",
    "            \n",
    "            print(classification_report(y_true, y_predicted))\n",
    "\n",
    "            print(\"Confusion matrix\")\n",
    "            print(cm)\n",
    "    return cl\n",
    "            \n",
    "#validation_indices_truelabeled=[]\n",
    "#validation_true_labels=[]\n",
    "#    test_data_extracted=data_extracted[test]\n",
    "#    for l in range(len(data_extracted[test])):\n",
    "#        if (label[train][l]!=-1):\n",
    "           #labeled_data_extracted.iloc[i,:]=test_data_extrated.iloc[l,:]\n",
    "#            test_indices_truelabeled_list.append(l)\n",
    "#            test_true_labels.append(label[train][l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
